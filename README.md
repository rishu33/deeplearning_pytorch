# Deep Learning with PyTorch - Course Notes & Code

Welcome! üëã  
This repository documents my journey through the Coursera course ["Deep Learning with PyTorch"](https://www.coursera.org/learn/advanced-deep-learning-with-pytorch).

---

## üìö Course Overview

This course focuses on implementing key deep learning concepts using PyTorch. You'll explore:

- Softmax regression and its application in multi-class classification
- Training shallow and deep neural networks
- Advanced training techniques like dropout, batch normalization, and weight initialization
- Convolutional Neural Networks (CNNs)
- Activation functions including ReLU, Sigmoid, and Tanh
- A final project using CNNs to classify images from the MNIST dataset

---

## üóÇÔ∏è Course Modules

| Module | Title | Description |
|--------|-------|-------------|
| **1** | Logistic Regression & Cross Entropy Loss | Explore why mean squared error is problematic for classification and implement cross entropy loss using PyTorch. |
| **2** | Softmax Regression | Learn about Softmax, argmax, and build a classifier using PyTorch's `nn.Module`. |
| **3** | Shallow Neural Networks | Build neural networks with hidden layers and understand overfitting, underfitting, and activation functions. |
| **4** | Deep Networks | Construct deep neural networks with dropout, weight initialization, batch normalization, and more. |
| **5** | Convolutional Neural Networks | Learn convolution operations, max pooling, multi-channel inputs, GPU acceleration, and ResNet-18. |
| **6** | Final Project | Implement a complete CNN model using PyTorch to classify MNIST images. |
